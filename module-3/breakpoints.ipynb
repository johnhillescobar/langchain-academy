{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1012a788",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-3/breakpoints.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239469-lesson-2-breakpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aa16f5-abc8-4ed3-8a71-54837fe46917",
   "metadata": {},
   "source": [
    "# Breakpoints\n",
    "\n",
    "## Review\n",
    "\n",
    "For `human-in-the-loop`, we often want to see our graph outputs as its running. \n",
    "\n",
    "We laid the foundations for this with streaming. \n",
    "\n",
    "## Goals\n",
    "\n",
    "Now, let's talk about the motivations for `human-in-the-loop`:\n",
    "\n",
    "(1) `Approval` - We can interrupt our agent, surface state to a user, and allow the user to accept an action\n",
    "\n",
    "(2) `Debugging` - We can rewind the graph to reproduce or avoid issues\n",
    "\n",
    "(3) `Editing` - You can modify the state \n",
    "\n",
    "LangGraph offers several ways to get or update agent state to support various `human-in-the-loop` workflows.\n",
    "\n",
    "First, we'll introduce [breakpoints](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/breakpoints/#simple-usage), which provide a simple way to stop the graph at specific steps. \n",
    "\n",
    "We'll show how this enables user `approval`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35842345-0694-4f0a-aa62-7d4898abf653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture --no-stderr\n",
    "# %pip install --quiet -U langgraph langchain_openai langgraph_sdk langgraph-prebuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67d91f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-proj-****************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# import getpass\n",
    "\n",
    "# def _set_env(var: str):\n",
    "#     if not os.environ.get(var):\n",
    "#         os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# _set_env(\"OPENAI_API_KEY\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(openai_api_key[:8]+ (len(openai_api_key)-8)*\"*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d8b4cd-e3ff-48cc-b7b2-f83fadb1c86b",
   "metadata": {},
   "source": [
    "## Breakpoints for human approval\n",
    "\n",
    "Let's re-consider the simple agent that we worked with in Module 1. \n",
    "\n",
    "Let's assume that are concerned about tool use: we want to approve the agent to use any of its tools.\n",
    " \n",
    "All we need to do is simply compile the graph with `interrupt_before=[\"tools\"]` where `tools` is our tools node.\n",
    "\n",
    "This means that the execution will be interrupted before the node `tools`, which executes the tool call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b94d1a90-2fe3-4b2a-a901-3bdb89e37edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "# This will be a tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide a by b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "tools = [add, multiply, divide]\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac06feae-d12b-490b-95e7-38cf40b74202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "# System message\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")\n",
    "\n",
    "# Node\n",
    "def assistant(state: MessagesState):\n",
    "   return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Define edges: these determine the control flow\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(interrupt_before=[\"tools\"], checkpointer=memory)\n",
    "\n",
    "# Show\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a783efac-46a9-4fb4-a1c6-a11b02540448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_fzK9A8BgTpANauLuMuTpBto2)\n",
      " Call ID: call_fzK9A8BgTpANauLuMuTpBto2\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "initial_input = {\"messages\": HumanMessage(content=\"Multiply 2 and 3\")}\n",
    "\n",
    "# Thread\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d49669-b1a5-42c2-bdb8-052da89bd7c4",
   "metadata": {},
   "source": [
    "We can get the state and look at the next node to call.\n",
    "\n",
    "This is a nice way to see that the graph has been interrupted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61569596-8342-4a37-9c99-e3a9dccb18ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tools',)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = graph.get_state(thread)\n",
    "state.next"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2fea0fb5-3145-4f34-bcc0-9c9e8972d6b4",
   "metadata": {},
   "source": [
    "Now, we'll introduce a nice trick.\n",
    "\n",
    "When we invoke the graph with `None`, it will just continue from the last state checkpoint!\n",
    "\n",
    "![breakpoints.jpg](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbae7985b747dfed67775d_breakpoints1.png)\n",
    "\n",
    "For clarity, LangGraph will re-emit the current state, which contains the `AIMessage` with tool call.\n",
    "\n",
    "And then it will proceed to execute the following steps in the graph, which start with the tool node.\n",
    "\n",
    "We see that the tool node is run with this tool call, and it's passed back to the chat model for our final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "896a5f41-7386-4bfa-a78e-3e6ca5e26641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_fzK9A8BgTpANauLuMuTpBto2)\n",
      " Call ID: call_fzK9A8BgTpANauLuMuTpBto2\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "6\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of multiplying 2 and 3 is 6.\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f91a0c-7cc1-4437-adc7-b36abb29beb1",
   "metadata": {},
   "source": [
    "Now, lets bring these together with a specific user approval step that accepts user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95a0eb50-66e3-4538-8103-207aae175154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_id5J8zKGdEL39D1RFN26H6al)\n",
      " Call ID: call_id5J8zKGdEL39D1RFN26H6al\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_id5J8zKGdEL39D1RFN26H6al)\n",
      " Call ID: call_id5J8zKGdEL39D1RFN26H6al\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "6\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of multiplying 2 and 3 is 6.\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "initial_input = {\"messages\": HumanMessage(content=\"Multiply 2 and 3\")}\n",
    "\n",
    "# Thread\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()\n",
    "\n",
    "# Get user feedback\n",
    "user_approval = input(\"Do you want to call the tool? (yes/no): \")\n",
    "\n",
    "# Check approval\n",
    "if user_approval.lower() == \"yes\":\n",
    "    \n",
    "    # If approved, continue the graph execution\n",
    "    for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "        event['messages'][-1].pretty_print()\n",
    "        \n",
    "else:\n",
    "    print(\"Operation cancelled by user.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8ff8762-6fa1-4373-954a-e7f479ee0efb",
   "metadata": {},
   "source": [
    "### Breakpoints with LangGraph API\n",
    "\n",
    "**⚠️ DISCLAIMER**\n",
    "\n",
    "Since the filming of these videos, we've updated Studio so that it can be run locally and opened in your browser. This is now the preferred way to run Studio (rather than using the Desktop App as shown in the video). See documentation [here](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/#local-development-server) on the local development server and [here](https://langchain-ai.github.io/langgraph/how-tos/local-studio/#run-the-development-server). To start the local development server, run the following command in your terminal in the `/studio` directory in this module:\n",
    "\n",
    "```\n",
    "langgraph dev\n",
    "```\n",
    "\n",
    "You should see the following output:\n",
    "```\n",
    "- 🚀 API: http://127.0.0.1:2024\n",
    "- 🎨 Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "- 📚 API Docs: http://127.0.0.1:2024/docs\n",
    "```\n",
    "\n",
    "Open your browser and navigate to the Studio UI: `https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024`.\n",
    "\n",
    "The LangGraph API [supports breakpoints](https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_breakpoint/#sdk-initialization). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63c2eaf1-6b8b-4d80-9902-98ae5587bcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'google.colab' in str(get_ipython()):\n",
    "#     raise Exception(\"Unfortunately LangGraph Studio is currently not supported on Google Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb1dd890-c216-4802-9e33-b637e491e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the URL of the local development server\n",
    "from langgraph_sdk import get_client\n",
    "client = get_client(url=\"http://127.0.0.1:2024\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e80d969-d065-45d7-8bfc-a403a0a1079b",
   "metadata": {},
   "source": [
    "As shown above, we can add `interrupt_before=[\"node\"]` when compiling the graph that is running in Studio.\n",
    "\n",
    "However, with the API, you can also pass `interrupt_before` to the stream method directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de9c5017-3a15-46f6-8edf-3997613da323",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectError",
     "evalue": "All connection attempts failed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py:101\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py:394\u001b[39m, in \u001b[36mAsyncHTTPTransport.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m     resp = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pool.handle_async_request(req)\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.AsyncIterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py:256\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py:236\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m connection.handle_async_request(\n\u001b[32m    237\u001b[39m         pool_request.request\n\u001b[32m    238\u001b[39m     )\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection.py:101\u001b[39m, in \u001b[36mAsyncHTTPConnection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.handle_async_request(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection.py:78\u001b[39m, in \u001b[36mAsyncHTTPConnection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     stream = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connect(request)\n\u001b[32m     80\u001b[39m     ssl_object = stream.get_extra_info(\u001b[33m\"\u001b[39m\u001b[33mssl_object\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection.py:124\u001b[39m, in \u001b[36mAsyncHTTPConnection._connect\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mconnect_tcp\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     stream = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._network_backend.connect_tcp(**kwargs)\n\u001b[32m    125\u001b[39m     trace.return_value = stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\httpcore\\_backends\\auto.py:31\u001b[39m, in \u001b[36mAutoBackend.connect_tcp\u001b[39m\u001b[34m(self, host, port, timeout, local_address, socket_options)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._init_backend()\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.connect_tcp(\n\u001b[32m     32\u001b[39m     host,\n\u001b[32m     33\u001b[39m     port,\n\u001b[32m     34\u001b[39m     timeout=timeout,\n\u001b[32m     35\u001b[39m     local_address=local_address,\n\u001b[32m     36\u001b[39m     socket_options=socket_options,\n\u001b[32m     37\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\httpcore\\_backends\\anyio.py:113\u001b[39m, in \u001b[36mAnyIOBackend.connect_tcp\u001b[39m\u001b[34m(self, host, port, timeout, local_address, socket_options)\u001b[39m\n\u001b[32m    108\u001b[39m exc_map = {\n\u001b[32m    109\u001b[39m     \u001b[38;5;167;01mTimeoutError\u001b[39;00m: ConnectTimeout,\n\u001b[32m    110\u001b[39m     \u001b[38;5;167;01mOSError\u001b[39;00m: ConnectError,\n\u001b[32m    111\u001b[39m     anyio.BrokenResourceError: ConnectError,\n\u001b[32m    112\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43manyio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfail_after\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py:155\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     \u001b[38;5;28mself\u001b[39m.gen.throw(typ, value, traceback)\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    157\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    158\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    159\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\httpcore\\_exceptions.py:14\u001b[39m, in \u001b[36mmap_exceptions\u001b[39m\u001b[34m(map)\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mConnectError\u001b[39m: All connection attempts failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mConnectError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m initial_input = {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33mMultiply 2 and 3\u001b[39m\u001b[33m\"\u001b[39m)}\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m thread = \u001b[38;5;28;01mawait\u001b[39;00m client.threads.create()\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m client.runs.stream(\n\u001b[32m      4\u001b[39m     thread[\u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      5\u001b[39m     assistant_id=\u001b[33m\"\u001b[39m\u001b[33magent\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m     interrupt_before=[\u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      9\u001b[39m ):\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReceiving new event of type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk.event\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\langgraph_sdk\\client.py:1113\u001b[39m, in \u001b[36mThreadsClient.create\u001b[39m\u001b[34m(self, metadata, thread_id, if_exists, supersteps, graph_id, headers)\u001b[39m\n\u001b[32m   1098\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m supersteps:\n\u001b[32m   1099\u001b[39m     payload[\u001b[33m\"\u001b[39m\u001b[33msupersteps\u001b[39m\u001b[33m\"\u001b[39m] = [\n\u001b[32m   1100\u001b[39m         {\n\u001b[32m   1101\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mupdates\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m   (...)\u001b[39m\u001b[32m   1110\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m supersteps\n\u001b[32m   1111\u001b[39m     ]\n\u001b[32m-> \u001b[39m\u001b[32m1113\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.http.post(\u001b[33m\"\u001b[39m\u001b[33m/threads\u001b[39m\u001b[33m\"\u001b[39m, json=payload, headers=headers)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\langgraph_sdk\\client.py:288\u001b[39m, in \u001b[36mHttpClient.post\u001b[39m\u001b[34m(self, path, json, headers, on_response)\u001b[39m\n\u001b[32m    286\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m headers:\n\u001b[32m    287\u001b[39m     request_headers.update(headers)\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m r = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.client.post(path, headers=request_headers, content=content)\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_response:\n\u001b[32m    290\u001b[39m     on_response(r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\httpx\\_client.py:1859\u001b[39m, in \u001b[36mAsyncClient.post\u001b[39m\u001b[34m(self, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m   1838\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1839\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1840\u001b[39m     url: URL | \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1852\u001b[39m     extensions: RequestExtensions | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1853\u001b[39m ) -> Response:\n\u001b[32m   1854\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1855\u001b[39m \u001b[33;03m    Send a `POST` request.\u001b[39;00m\n\u001b[32m   1856\u001b[39m \n\u001b[32m   1857\u001b[39m \u001b[33;03m    **Parameters**: See `httpx.request`.\u001b[39;00m\n\u001b[32m   1858\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1859\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(\n\u001b[32m   1860\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPOST\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1861\u001b[39m         url,\n\u001b[32m   1862\u001b[39m         content=content,\n\u001b[32m   1863\u001b[39m         data=data,\n\u001b[32m   1864\u001b[39m         files=files,\n\u001b[32m   1865\u001b[39m         json=json,\n\u001b[32m   1866\u001b[39m         params=params,\n\u001b[32m   1867\u001b[39m         headers=headers,\n\u001b[32m   1868\u001b[39m         cookies=cookies,\n\u001b[32m   1869\u001b[39m         auth=auth,\n\u001b[32m   1870\u001b[39m         follow_redirects=follow_redirects,\n\u001b[32m   1871\u001b[39m         timeout=timeout,\n\u001b[32m   1872\u001b[39m         extensions=extensions,\n\u001b[32m   1873\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\httpx\\_client.py:1540\u001b[39m, in \u001b[36mAsyncClient.request\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m   1525\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m   1527\u001b[39m request = \u001b[38;5;28mself\u001b[39m.build_request(\n\u001b[32m   1528\u001b[39m     method=method,\n\u001b[32m   1529\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1538\u001b[39m     extensions=extensions,\n\u001b[32m   1539\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.send(request, auth=auth, follow_redirects=follow_redirects)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\httpx\\_client.py:1629\u001b[39m, in \u001b[36mAsyncClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m   1625\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m   1627\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m-> \u001b[39m\u001b[32m1629\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_auth(\n\u001b[32m   1630\u001b[39m     request,\n\u001b[32m   1631\u001b[39m     auth=auth,\n\u001b[32m   1632\u001b[39m     follow_redirects=follow_redirects,\n\u001b[32m   1633\u001b[39m     history=[],\n\u001b[32m   1634\u001b[39m )\n\u001b[32m   1635\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1636\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\httpx\\_client.py:1657\u001b[39m, in \u001b[36mAsyncClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m   1654\u001b[39m request = \u001b[38;5;28;01mawait\u001b[39;00m auth_flow.\u001b[34m__anext__\u001b[39m()\n\u001b[32m   1656\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1657\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_redirects(\n\u001b[32m   1658\u001b[39m         request,\n\u001b[32m   1659\u001b[39m         follow_redirects=follow_redirects,\n\u001b[32m   1660\u001b[39m         history=history,\n\u001b[32m   1661\u001b[39m     )\n\u001b[32m   1662\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1663\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\httpx\\_client.py:1694\u001b[39m, in \u001b[36mAsyncClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m   1691\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   1692\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m hook(request)\n\u001b[32m-> \u001b[39m\u001b[32m1694\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_single_request(request)\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1696\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\httpx\\_client.py:1730\u001b[39m, in \u001b[36mAsyncClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1725\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1726\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an sync request with an AsyncClient instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1727\u001b[39m     )\n\u001b[32m   1729\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1730\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m transport.handle_async_request(request)\n\u001b[32m   1732\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, AsyncByteStream)\n\u001b[32m   1733\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py:393\u001b[39m, in \u001b[36mAsyncHTTPTransport.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhttpcore\u001b[39;00m\n\u001b[32m    381\u001b[39m req = httpcore.Request(\n\u001b[32m    382\u001b[39m     method=request.method,\n\u001b[32m    383\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     extensions=request.extensions,\n\u001b[32m    392\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_httpcore_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mawait\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_async_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.AsyncIterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py:155\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    153\u001b[39m     value = typ()\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     \u001b[38;5;28mself\u001b[39m.gen.throw(typ, value, traceback)\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    157\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    158\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    159\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[32m    160\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py:118\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    117\u001b[39m message = \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mConnectError\u001b[39m: All connection attempts failed"
     ]
    }
   ],
   "source": [
    "initial_input = {\"messages\": HumanMessage(content=\"Multiply 2 and 3\")}\n",
    "thread = await client.threads.create()\n",
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input=initial_input,\n",
    "    stream_mode=\"values\",\n",
    "    interrupt_before=[\"tools\"],\n",
    "):\n",
    "    print(f\"Receiving new event of type: {chunk.event}...\")\n",
    "    messages = chunk.data.get('messages', [])\n",
    "    if messages:\n",
    "        print(messages[-1])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813b6ca0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b64272d1-c6ee-435f-9890-9b6c3525ca6c",
   "metadata": {},
   "source": [
    "Now, we can proceed from the breakpoint just like we did before by passing the `thread_id` and `None` as the input!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76284730-9c90-46c4-8295-400a49760b07",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'thread_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m client.runs.stream(\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mthread\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthread_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33magent\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m     \u001b[38;5;28minput\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m      5\u001b[39m     stream_mode=\u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m     interrupt_before=[\u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      7\u001b[39m ):\n\u001b[32m      8\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReceiving new event of type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk.event\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m     messages = chunk.data.get(\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m, [])\n",
      "\u001b[31mKeyError\u001b[39m: 'thread_id'"
     ]
    }
   ],
   "source": [
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    \"agent\",\n",
    "    input=None,\n",
    "    stream_mode=\"values\",\n",
    "    interrupt_before=[\"tools\"],\n",
    "):\n",
    "    print(f\"Receiving new event of type: {chunk.event}...\")\n",
    "    messages = chunk.data.get('messages', [])\n",
    "    if messages:\n",
    "        print(messages[-1])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4575970f-42e2-4d03-b18a-aacaa8233b53",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
