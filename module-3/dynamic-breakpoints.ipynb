{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2109e6a2",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-3/dynamic-breakpoints.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239526-lesson-4-dynamic-breakpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cefea1-f982-4bb1-b691-27a855bfdccb",
   "metadata": {},
   "source": [
    "# Dynamic breakpoints \n",
    "\n",
    "## Review\n",
    "\n",
    "We discussed motivations for human-in-the-loop:\n",
    "\n",
    "(1) `Approval` - We can interrupt our agent, surface state to a user, and allow the user to accept an action\n",
    "\n",
    "(2) `Debugging` - We can rewind the graph to reproduce or avoid issues\n",
    "\n",
    "(3) `Editing` - You can modify the state \n",
    "\n",
    "We covered breakpoints as a general way to stop the graph at specific steps, which enables use-cases like `Approval`\n",
    "\n",
    "We also showed how to edit graph state, and introduce human feedback. \n",
    "\n",
    "## Goals\n",
    "\n",
    "Breakpoints are set by the developer on a specific node during graph compilation. \n",
    "\n",
    "But, sometimes it is helpful to allow the graph **dynamically interrupt** itself!\n",
    "\n",
    "This is an internal breakpoint, and [can be achieved using the `interrupt` function](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/dynamic_breakpoints/#run-the-graph-with-dynamic-interrupt).\n",
    "\n",
    "This has a few specific benefits: \n",
    "\n",
    "(1) you can do it conditionally (from inside a node based on developer-defined logic).\n",
    "\n",
    "(2) you can communicate to the user why its interrupted (by passing whatever you want to the `interrupt` function).\n",
    "\n",
    "Let's create a graph where an `interrupt` is called based upon length of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "387d8d87-598a-485a-a99f-a9270a7c2e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture --no-stderr\n",
    "# %pip install --quiet -U langgraph langchain_openai langgraph_sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6248f166-2013-445a-b4ae-1fb7b92f8c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "# from langgraph.errors import NodeInterrupt\n",
    "from langgraph.types import interrupt\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "\n",
    "class State(TypedDict):\n",
    "    input: str\n",
    "\n",
    "def step_1(state: State) -> State:\n",
    "    print(\"---Step 1---\")\n",
    "    return state\n",
    "\n",
    "def step_2(state: State) -> State:\n",
    "    # Let's optionally raise a NodeInterrupt if the length of the input is longer than 5 characters\n",
    "    if len(state['input']) > 5:\n",
    "        raise interrupt(f\"Received input that is longer than 5 characters: {state['input']}\")\n",
    "    \n",
    "    print(\"---Step 2---\")\n",
    "    return state\n",
    "\n",
    "def step_3(state: State) -> State:\n",
    "    print(\"---Step 3---\")\n",
    "    return state\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"step_1\", step_1)\n",
    "builder.add_node(\"step_2\", step_2)\n",
    "builder.add_node(\"step_3\", step_3)\n",
    "builder.add_edge(START, \"step_1\")\n",
    "builder.add_edge(\"step_1\", \"step_2\")\n",
    "builder.add_edge(\"step_2\", \"step_3\")\n",
    "builder.add_edge(\"step_3\", END)\n",
    "\n",
    "# Set up memory\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Compile the graph with memory\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c6e5c8-0556-43d1-9eef-b3af32728f74",
   "metadata": {},
   "source": [
    "Let's run the graph with an input that's longer than 5 characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de73c9ce-ccc5-4ffd-8d82-7018364e7c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'hello world'}\n",
      "---Step 1---\n",
      "{'input': 'hello world'}\n"
     ]
    }
   ],
   "source": [
    "initial_input = {\"input\": \"hello world\"}\n",
    "thread_config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "for event in graph.stream(initial_input, thread_config, stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3badfa0a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da79063f-5b67-49dd-8ef0-3eae4c480cb5",
   "metadata": {},
   "source": [
    "If we inspect the graph state at this point, we the node set to execute next (`step_2`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34706f0d-379b-4236-a42e-c8e52b27fb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('step_2',)\n"
     ]
    }
   ],
   "source": [
    "state = graph.get_state(thread_config)\n",
    "print(state.next)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed78755-f1e8-4c66-a4f8-a7ccff472c91",
   "metadata": {},
   "source": [
    "We can see that the `Interrupt` is logged to state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93815a05-819a-4050-8834-73236fa910dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(PregelTask(id='2ad26602-5675-ea8f-f07e-5c8e352845cc', name='step_2', path=('__pregel_pull', 'step_2'), error=None, interrupts=(Interrupt(value='Received input that is longer than 5 characters: hello world', id='8b20ba775f1eb8e15dd5478ca29b0989'),), state=None, result=None),)\n"
     ]
    }
   ],
   "source": [
    "print(state.tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d74573-b62c-4ac1-a142-d04c2dccfd08",
   "metadata": {},
   "source": [
    "We can try to resume the graph from the breakpoint. \n",
    "\n",
    "But, this just re-runs the same node! \n",
    "\n",
    "Unless state is changed we will be stuck here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b735875e-62c6-4253-ba85-7ccf93a353b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'hello world'}\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream(None, thread_config, stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e3bc5e3-7a2f-49a1-8bdc-fd3597bd5fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('step_2',)\n"
     ]
    }
   ],
   "source": [
    "state = graph.get_state(thread_config)\n",
    "print(state.next)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ab61de-5c3f-44a5-b417-e36b1a2f26dd",
   "metadata": {},
   "source": [
    "Now, we can update state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f08dff4-3399-46de-a9ba-ba89b8cdb61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f07ef71-3c79-624c-8002-ccde390745e8'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.update_state(\n",
    "    thread_config,\n",
    "    {\"input\": \"hi\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cb3f62b-fccd-47c3-af1e-541969e4d804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'hi'}\n",
      "---Step 2---\n",
      "{'input': 'hi'}\n",
      "---Step 3---\n",
      "{'input': 'hi'}\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream(None, thread_config, stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76e3dea8-8270-42c7-8d24-606b79b9c6aa",
   "metadata": {},
   "source": [
    "### Usage with LangGraph API\n",
    "\n",
    "**âš ï¸ DISCLAIMER**\n",
    "\n",
    "Since the filming of these videos, we've updated Studio so that it can be run locally and opened in your browser. This is now the preferred way to run Studio (rather than using the Desktop App as shown in the video). See documentation [here](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/#local-development-server) on the local development server and [here](https://langchain-ai.github.io/langgraph/how-tos/local-studio/#run-the-development-server). To start the local development server, run the following command in your terminal in the `/studio` directory in this module:\n",
    "\n",
    "```\n",
    "langgraph dev\n",
    "```\n",
    "\n",
    "You should see the following output:\n",
    "```\n",
    "- ðŸš€ API: http://127.0.0.1:2024\n",
    "- ðŸŽ¨ Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "- ðŸ“š API Docs: http://127.0.0.1:2024/docs\n",
    "```\n",
    "\n",
    "Open your browser and navigate to the Studio UI: `https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be02c417-5adc-4789-aa90-02fd2312eb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    raise Exception(\"Unfortunately LangGraph Studio is currently not supported on Google Colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2390ff2e-6b1a-4c6e-b0ce-debd45085dc8",
   "metadata": {},
   "source": [
    "We connect to it via the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4696327d",
   "metadata": {},
   "outputs": [
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m client = get_client(url=URL)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Search all hosted graphs\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m assistants = \u001b[38;5;28;01mawait\u001b[39;00m client.assistants.search()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\langgraph_sdk\\client.py:913\u001b[39m, in \u001b[36mAssistantsClient.search\u001b[39m\u001b[34m(self, metadata, graph_id, limit, offset, sort_by, sort_order, headers)\u001b[39m\n\u001b[32m    911\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sort_order:\n\u001b[32m    912\u001b[39m     payload[\u001b[33m\"\u001b[39m\u001b[33msort_order\u001b[39m\u001b[33m\"\u001b[39m] = sort_order\n\u001b[32m--> \u001b[39m\u001b[32m913\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.http.post(\n\u001b[32m    914\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m/assistants/search\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    915\u001b[39m     json=payload,\n\u001b[32m    916\u001b[39m     headers=headers,\n\u001b[32m    917\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\langgraph_sdk\\client.py:288\u001b[39m, in \u001b[36mHttpClient.post\u001b[39m\u001b[34m(self, path, json, headers, on_response)\u001b[39m\n\u001b[32m    286\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m headers:\n\u001b[32m    287\u001b[39m     request_headers.update(headers)\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m r = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.client.post(path, headers=request_headers, content=content)\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_response:\n\u001b[32m    290\u001b[39m     on_response(r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\httpx\\_client.py:1859\u001b[39m, in \u001b[36mAsyncClient.post\u001b[39m\u001b[34m(self, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m   1838\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1839\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1840\u001b[39m     url: URL | \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1852\u001b[39m     extensions: RequestExtensions | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1853\u001b[39m ) -> Response:\n\u001b[32m   1854\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1855\u001b[39m \u001b[33;03m    Send a `POST` request.\u001b[39;00m\n\u001b[32m   1856\u001b[39m \n\u001b[32m   1857\u001b[39m \u001b[33;03m    **Parameters**: See `httpx.request`.\u001b[39;00m\n\u001b[32m   1858\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1859\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(\n\u001b[32m   1860\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPOST\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1861\u001b[39m         url,\n\u001b[32m   1862\u001b[39m         content=content,\n\u001b[32m   1863\u001b[39m         data=data,\n\u001b[32m   1864\u001b[39m         files=files,\n\u001b[32m   1865\u001b[39m         json=json,\n\u001b[32m   1866\u001b[39m         params=params,\n\u001b[32m   1867\u001b[39m         headers=headers,\n\u001b[32m   1868\u001b[39m         cookies=cookies,\n\u001b[32m   1869\u001b[39m         auth=auth,\n\u001b[32m   1870\u001b[39m         follow_redirects=follow_redirects,\n\u001b[32m   1871\u001b[39m         timeout=timeout,\n\u001b[32m   1872\u001b[39m         extensions=extensions,\n\u001b[32m   1873\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\httpx\\_client.py:1540\u001b[39m, in \u001b[36mAsyncClient.request\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m   1525\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m   1527\u001b[39m request = \u001b[38;5;28mself\u001b[39m.build_request(\n\u001b[32m   1528\u001b[39m     method=method,\n\u001b[32m   1529\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1538\u001b[39m     extensions=extensions,\n\u001b[32m   1539\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.send(request, auth=auth, follow_redirects=follow_redirects)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\httpx\\_client.py:1629\u001b[39m, in \u001b[36mAsyncClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m   1625\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m   1627\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m-> \u001b[39m\u001b[32m1629\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_auth(\n\u001b[32m   1630\u001b[39m     request,\n\u001b[32m   1631\u001b[39m     auth=auth,\n\u001b[32m   1632\u001b[39m     follow_redirects=follow_redirects,\n\u001b[32m   1633\u001b[39m     history=[],\n\u001b[32m   1634\u001b[39m )\n\u001b[32m   1635\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1636\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\httpx\\_client.py:1657\u001b[39m, in \u001b[36mAsyncClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m   1654\u001b[39m request = \u001b[38;5;28;01mawait\u001b[39;00m auth_flow.\u001b[34m__anext__\u001b[39m()\n\u001b[32m   1656\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1657\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_redirects(\n\u001b[32m   1658\u001b[39m         request,\n\u001b[32m   1659\u001b[39m         follow_redirects=follow_redirects,\n\u001b[32m   1660\u001b[39m         history=history,\n\u001b[32m   1661\u001b[39m     )\n\u001b[32m   1662\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1663\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\httpx\\_client.py:1694\u001b[39m, in \u001b[36mAsyncClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m   1691\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   1692\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m hook(request)\n\u001b[32m-> \u001b[39m\u001b[32m1694\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_single_request(request)\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1696\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\httpx\\_client.py:1730\u001b[39m, in \u001b[36mAsyncClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1725\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1726\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an sync request with an AsyncClient instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1727\u001b[39m     )\n\u001b[32m   1729\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1730\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m transport.handle_async_request(request)\n\u001b[32m   1732\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, AsyncByteStream)\n\u001b[32m   1733\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py:394\u001b[39m, in \u001b[36mAsyncHTTPTransport.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    381\u001b[39m req = httpcore.Request(\n\u001b[32m    382\u001b[39m     method=request.method,\n\u001b[32m    383\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     extensions=request.extensions,\n\u001b[32m    392\u001b[39m )\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m     resp = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pool.handle_async_request(req)\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.AsyncIterable)\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    399\u001b[39m     status_code=resp.status,\n\u001b[32m    400\u001b[39m     headers=resp.headers,\n\u001b[32m    401\u001b[39m     stream=AsyncResponseStream(resp.stream),\n\u001b[32m    402\u001b[39m     extensions=resp.extensions,\n\u001b[32m    403\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py:256\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.AsyncIterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py:236\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = \u001b[38;5;28;01mawait\u001b[39;00m pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m connection.handle_async_request(\n\u001b[32m    237\u001b[39m         pool_request.request\n\u001b[32m    238\u001b[39m     )\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection.py:101\u001b[39m, in \u001b[36mAsyncHTTPConnection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.handle_async_request(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection.py:78\u001b[39m, in \u001b[36mAsyncHTTPConnection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._request_lock:\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m         stream = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connect(request)\n\u001b[32m     80\u001b[39m         ssl_object = stream.get_extra_info(\u001b[33m\"\u001b[39m\u001b[33mssl_object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     81\u001b[39m         http2_negotiated = (\n\u001b[32m     82\u001b[39m             ssl_object \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     83\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m ssl_object.selected_alpn_protocol() == \u001b[33m\"\u001b[39m\u001b[33mh2\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     84\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection.py:124\u001b[39m, in \u001b[36mAsyncHTTPConnection._connect\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    116\u001b[39m     kwargs = {\n\u001b[32m    117\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhost\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._origin.host.decode(\u001b[33m\"\u001b[39m\u001b[33mascii\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    118\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mport\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._origin.port,\n\u001b[32m   (...)\u001b[39m\u001b[32m    121\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msocket_options\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._socket_options,\n\u001b[32m    122\u001b[39m     }\n\u001b[32m    123\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mconnect_tcp\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m         stream = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._network_backend.connect_tcp(**kwargs)\n\u001b[32m    125\u001b[39m         trace.return_value = stream\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\httpcore\\_backends\\auto.py:31\u001b[39m, in \u001b[36mAutoBackend.connect_tcp\u001b[39m\u001b[34m(self, host, port, timeout, local_address, socket_options)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect_tcp\u001b[39m(\n\u001b[32m     23\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     24\u001b[39m     host: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m     socket_options: typing.Iterable[SOCKET_OPTION] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     29\u001b[39m ) -> AsyncNetworkStream:\n\u001b[32m     30\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._init_backend()\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.connect_tcp(\n\u001b[32m     32\u001b[39m         host,\n\u001b[32m     33\u001b[39m         port,\n\u001b[32m     34\u001b[39m         timeout=timeout,\n\u001b[32m     35\u001b[39m         local_address=local_address,\n\u001b[32m     36\u001b[39m         socket_options=socket_options,\n\u001b[32m     37\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\httpcore\\_backends\\anyio.py:115\u001b[39m, in \u001b[36mAnyIOBackend.connect_tcp\u001b[39m\u001b[34m(self, host, port, timeout, local_address, socket_options)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m anyio.fail_after(timeout):\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m         stream: anyio.abc.ByteStream = \u001b[38;5;28;01mawait\u001b[39;00m anyio.connect_tcp(\n\u001b[32m    116\u001b[39m             remote_host=host,\n\u001b[32m    117\u001b[39m             remote_port=port,\n\u001b[32m    118\u001b[39m             local_host=local_address,\n\u001b[32m    119\u001b[39m         )\n\u001b[32m    120\u001b[39m         \u001b[38;5;66;03m# By default TCP sockets opened in `asyncio` include TCP_NODELAY.\u001b[39;00m\n\u001b[32m    121\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m option \u001b[38;5;129;01min\u001b[39;00m socket_options:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\anyio\\_core\\_sockets.py:235\u001b[39m, in \u001b[36mconnect_tcp\u001b[39m\u001b[34m(remote_host, remote_port, local_host, tls, ssl_context, tls_standard_compatible, tls_hostname, happy_eyeballs_delay)\u001b[39m\n\u001b[32m    233\u001b[39m oserrors: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;167;01mOSError\u001b[39;00m] = []\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m create_task_group() \u001b[38;5;28;01mas\u001b[39;00m tg:\n\u001b[32m    236\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m _af, addr \u001b[38;5;129;01min\u001b[39;00m target_addrs:\n\u001b[32m    237\u001b[39m             event = Event()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py:776\u001b[39m, in \u001b[36mTaskGroup.__aexit__\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    772\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m BaseExceptionGroup(\n\u001b[32m    773\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33munhandled errors in a TaskGroup\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._exceptions\n\u001b[32m    774\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    775\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m exc_val:\n\u001b[32m--> \u001b[39m\u001b[32m776\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m exc_val\n\u001b[32m    777\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    778\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cancel_scope.\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mtype\u001b[39m(exc), exc, exc.__traceback__):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\langchain-academy\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py:744\u001b[39m, in \u001b[36mTaskGroup.__aexit__\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    741\u001b[39m \u001b[38;5;28mself\u001b[39m._on_completed_fut = loop.create_future()\n\u001b[32m    743\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m744\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._on_completed_fut\n\u001b[32m    745\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m CancelledError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    746\u001b[39m     \u001b[38;5;66;03m# Shield the scope against further cancellation attempts,\u001b[39;00m\n\u001b[32m    747\u001b[39m     \u001b[38;5;66;03m# as they're not productive (#695)\u001b[39;00m\n\u001b[32m    748\u001b[39m     wait_scope.shield = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "# This is the URL of the local development server\n",
    "URL = \"http://127.0.0.1:2024\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "# Search all hosted graphs\n",
    "assistants = await client.assistants.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb892cb-c79c-46bb-820b-d0479e71c5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = await client.threads.create()\n",
    "input_dict = {\"input\": \"hello world\"}\n",
    "\n",
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"dynamic_breakpoints\",\n",
    "    input=input_dict,\n",
    "    stream_mode=\"values\",):\n",
    "    \n",
    "    print(f\"Receiving new event of type: {chunk.event}...\")\n",
    "    print(chunk.data)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba7d9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_state = await client.threads.get_state(thread['thread_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9610fc2b-ae39-4ffa-84af-b049e7d22cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_state['next']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e880cf0-18b1-4f7b-a770-24d45dd22757",
   "metadata": {},
   "outputs": [],
   "source": [
    "await client.threads.update_state(thread['thread_id'], {\"input\": \"hi!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dc65b9-95c0-46eb-9f73-da0a35e70034",
   "metadata": {},
   "outputs": [],
   "source": [
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"dynamic_breakpoints\",\n",
    "    input=None,\n",
    "    stream_mode=\"values\",):\n",
    "    \n",
    "    print(f\"Receiving new event of type: {chunk.event}...\")\n",
    "    print(chunk.data)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f662b10-ad4c-45c7-a420-ded8ccae8faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_state = await client.threads.get_state(thread['thread_id'])\n",
    "current_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873b3696-df61-4f2e-94d8-089b7072aafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check LangGraph version using the correct method\n",
    "try:\n",
    "    from importlib.metadata import version\n",
    "    langgraph_version = version(\"langgraph\")\n",
    "    print(f\"LangGraph version: {langgraph_version}\")\n",
    "except ImportError:\n",
    "    # Fallback for older Python versions\n",
    "    import pkg_resources\n",
    "    try:\n",
    "        version = pkg_resources.get_distribution(\"langgraph\").version\n",
    "        print(f\"LangGraph version: {version}\")\n",
    "    except pkg_resources.DistributionNotFound:\n",
    "        print(\"LangGraph version not found\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not get version: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9fe139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import interrupt\n",
    "\n",
    "def human_node(state: State):\n",
    "    value = interrupt(\n",
    "        {\n",
    "            \"text_to_revise\": state[\"some_text\"]\n",
    "        }\n",
    "    )\n",
    "    return { \"some_text\": value }\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=checkpointer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
